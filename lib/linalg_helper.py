#!/usr/bin/env python
# Copyright 2014-2020 The PySCF Developers. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
# Author: Qiming Sun <osirpt.sun@gmail.com>
#

#
# Heavily modified by Vale Cofer-Shabica <vale.cofershabica@gmail.com>, 2025
#

import numpy as np

from sys import stdout
from pyscf.lib import logger

from debug import timer, timer_ctx
from time import perf_counter

def davidson1(aop, x0, precond, tol=1e-12, max_cycle=50, max_space=100,
              max_trial=40,
              lindep=1e-14, max_memory=8000,
              callback=None,
              nroots=1, verbose=logger.WARN,
              tol_residual=None,
              ):
    r"""Davidson diagonalization method to solve  a c = e c.  Ref
    [1] E.R. Davidson, J. Comput. Phys. 17 (1), 87-94 (1975).
    [2] http://people.inf.ethz.ch/arbenz/ewp/Lnotes/chapter11.pdf

    Note: This function has an overhead of memory usage ~4*x0.size*nroots

    Args:
        aop : function([x]) => [array_like_x]
            Matrix vector multiplication :math:`y_{ki} = \sum_{j}a_{ij}*x_{jk}`.
        x0 : 1D array or a list of 1D arrays or a function to generate x0 array(s)
            Initial guess.  The initial guess vector(s) are just used as the
            initial subspace bases.  If the subspace is smaller than "nroots",
            eg 10 roots and one initial guess, all eigenvectors are chosen as
            the eigenvectors during the iterations.  The first iteration has
            one eigenvector, the next iteration has two, the third iteration
            has 4, ..., until the subspace size > nroots.
        precond : diagonal elements of the matrix or  function(dx, e, x0) => array_like_dx
            Preconditioner to generate new trial vector.
            The argument dx is a residual vector ``a*x0-e*x0``; e is the current
            eigenvalue; x0 is the current eigenvector.

    Kwargs:
        tol : float
            Convergence tolerance.
        max_cycle : int
            max number of iterations.
        max_space : int
            space size to hold trial vectors.
        max_trial : int
            maximum trial vectors to work with at a time; only matters if max_trial < nroots
        lindep : float
            Linear dependency threshold.  The function is terminated when the
            smallest eigenvalue of the metric of the trial vectors is lower
            than this threshold.
        max_memory : int or float
            Allowed memory in MB.
        callback : function(envs_dict) => None
            callback function takes one dict as the argument which is
            generated by the builtin function :func:`locals`, so that the
            callback function can access all local variables in the current
            environment.
        nroots : int
            Number of eigenvalues to be computed.  When nroots > 1, it affects
            the shape of the return value

    Returns:
        conv : bool
            Converged or not
        e : list of floats
            The lowest :attr:`nroots` eigenvalues.
        c : list of 1D arrays
            The lowest :attr:`nroots` eigenvectors.

    Examples:

    >>> from pyscf import lib
    >>> a = np.random.random((10,10))
    >>> a = a + a.T
    >>> aop = lambda xs: [np.dot(a,x) for x in xs]
    >>> precond = lambda dx, e, x0: dx/(a.diagonal()-e)
    >>> x0 = a[0]
    >>> e, c = lib.davidson(aop, x0, precond, nroots=2)
    >>> len(e)
    2
    """
    if isinstance(verbose, logger.Logger):
        log = verbose
    else:
        log = logger.Logger(stdout, verbose)

    if tol_residual is None:
        tol_residual = np.sqrt(tol)

    log.debug1('tol %g  tol_residual %g', tol, tol_residual)

    if not callable(precond):
        precond = make_diag_precond(precond)

    x0 = np.atleast_2d(x0)
    Nelem = x0[0].size

    max_cycle = min(max_cycle, Nelem)
    max_space = max_space + (nroots-1) * 4
    # max_space*2 for holding ax and xs, nroots*2 for holding axt and xt
    required_memory = (max_space*2 + nroots*3) * x0[0].nbytes / 1024 / 1024
    allow_resize = False
    if  required_memory > max_memory:
        log.warn("Required space is %d MB, but max memory is %d MB. "
                 "Resizing will be allowed, but the performance penalty may be significant.", required_memory, max_memory)
        allow_resize = True
    log.debug1("max_cycle %d  max_space %d  Nelem %d  required_memory %dMB  max_memory %dMB  resize %s",
               max_cycle, max_space, Nelem, required_memory, max_memory, allow_resize)

    # FIXME: aop(x0) is a wasted calculation
    dtype = np.result_type(aop(x0), x0)
    log.debug("dtype=%s", dtype)
    
    if allow_resize:
        xs = np.empty((0, Nelem), dtype=dtype)
        ax = np.empty((0, Nelem), dtype=dtype)
    else:
        xs = np.empty((max_space, Nelem), dtype=dtype)
        ax = np.empty((max_space, Nelem), dtype=dtype)

    fresh_start = True
    heff = np.zeros((max_space,max_space), dtype=dtype)
    e = None
    v = None
    conv = np.zeros(nroots, dtype=bool)
    emin = None

    for icyc in range(max_cycle):
        if fresh_start:
            if allow_resize:
                xs = np.empty((0, Nelem))
                ax = np.empty((0, Nelem))

            space = 0
            xt = _qr(x0)

            if len(xt) != len(x0):
                log.warn('QR decomposition removed %d vectors.', x0len - len(xt))
                if len(xt) == 0:
                    if icyc == 0:
                        msg = 'Initial guess is empty or zero'
                    else:
                        msg = ('No more linearly independent basis were found. '
                               'Unless loosen the lindep tolerance (current value '
                               f'{lindep}), the diagonalization solver is not able '
                               'to find eigenvectors.')
                    raise RuntimeError(msg)

        elif len(xt) > 1:
            xt = _qr(xt)[:max_trial]

        axt = aop(xt)

        if allow_resize:
            xs = np.concat((xs, xt))
            ax = np.concat((ax, axt))
        else:
            nxt = len(xt)
            xs[space:space+nxt] = xt
            ax[space:space+nxt] = axt
        space += len(xt)

        elast = e
        vlast = v
        conv_last = conv

        _fill_heff_hermitian(heff, ax[:space], xt, axt)

        e, v = np.linalg.eigh(heff[:space,:space])
        e = e[:nroots]
        v = v[:,:nroots]

        if not fresh_start:
            elast, conv_last = _sort_elast(elast, conv_last, vlast, v, log)

        if elast is None:
            de = e
        elif elast.size != e.size:
            log.debug('Number of roots different from the previous step (%d,%d)',
                      e.size, elast.size)
            de = e
        else:
            de = e - elast

        x0 = _from_subspace(v, xs[:space])
        xt = _from_subspace(v, ax[:space]) - e[:,None]*x0
        dx_norm = np.linalg.norm(xt, axis=1)
        conv = (np.abs(de) < tol) & (dx_norm < tol_residual)

        for k, ek in enumerate(e):
            if conv[k] and not conv_last[k]:
                log.debug('root %d converged  |r|=%4.3g  e=%s  max|de|=%4.3g',
                          k, dx_norm[k], ek, de[k])
        
        ide = np.argmax(abs(de))

        if all(conv):
            log.debug('converged %d %d  |r|=%4.3g  e=%s  max|de|=%4.3g',
                      icyc, space, dx_norm.max(), e, de[ide])
            break

        # remove subspace linear dependencies
        keep = ~conv & (dx_norm > np.sqrt(lindep))
        xt = xt[keep]

        if len(xt) == 0:
            log.debug('Linear dependency in trial subspace. |r| for each state %s',
                      dx_norm)
            conv = dx_norm < tol_residual
            break

        xt = np.asarray([precond(xt_, e[0], x0_) for xt_, x0_ in zip(xt, x0[keep])])
        norms = np.linalg.norm(xt, axis=1)
        xt /= norms[:, None]

        xt, norm_min = _orthonormalize_xt(xt, xs[:space], lindep)
        log.debug('davidson %d %d  |r|=%4.3g  e=%s  max|de|=%4.3g  lindep=%4.3g',
                  icyc, space, dx_norm.max(), e, de[ide], norm_min)

        if icyc > 3 and de[0] > 0 and abs(de[0]) > tol:
            log.debug("Hold up! Why isn't de monotonic??? %s", de)

        fresh_start = space+nroots > max_space

        # useful, e.g., for restarts
        if callable(callback):
            callback(locals())

    foundroots, _ = x0.shape
    if foundroots < nroots:
        # Two possible reasons:
        # 1. All the initial guess are the eigenvectors. No more trial vectors
        # can be generated.
        # 2. The initial guess sits in the subspace which is smaller than the
        # required number of roots.
        log.warn(f'Not enough eigenvectors (len(x0)={len(x0)}, nroots={nroots})')

    return conv, e, x0


def make_diag_precond(diag, level_shift=1e-3):
    """Generate the preconditioner function with the diagonal function."""
    # For diagonal matrix A, precond (Ax-x*e)/(diag(A)-e) is not able to
    # generate linearly independent basis (see PySCF issue 1362). Use level_shift to
    # break the correlation between Ax-x*e and diag(A)-e.
    def precond(dx, e, *args):
        diagd = diag - (e - level_shift)
        diagd[abs(diagd)<1e-8] = 1e-8
        return dx/diagd
    return precond

def _qr(X):
    return (np.linalg.qr(X.T)[0]).T


def _from_subspace(v, xs):
    v = np.atleast_2d(v)
    x0 = np.einsum('ik,ij->kj', v, xs, optimize=True)

    return x0


def _sort_elast(elast, conv_last, vlast, v, log):
    """
    Eigenstates may be flipped during the Davidson iterations.  Reorder the
    eigenvalues of last iteration to make them comparable to the eigenvalues
    of the current iterations.
    """
    head, nroots = vlast.shape
    ovlp = abs(np.dot(v[:head].conj().T, vlast))
    mapping = np.argmax(ovlp, axis=1)
    found = np.any(ovlp > .5, axis=1)

    if log.verbose >= logger.DEBUG:
        ordering_diff = (mapping != np.arange(len(mapping)))
        if any(ordering_diff & found):
            log.debug('Old state -> New state')
            for i in np.where(ordering_diff)[0]:
                log.debug('  %3d     ->   %3d ', mapping[i], i)

    conv = conv_last[mapping]
    e = elast[mapping]
    conv[~found] = False
    e[~found] = 0.
    return e, conv


def _orthonormalize_xt(xt, xs, threshold):
    """Projects out existing basis vectors xs. Also checks whether the precond
    function is ill-conditioned"""

    # Project: xt_mat -= xs.T @ (xs @ xt_mat.T)
    # In detail: subtract each xi's projection onto the span of xs
    proj = xs @ xt.T     # shape: (nbasis, nvecs)
    xt -= (proj.T @ xs)  # shape: (nvecs, ndim)

    # Compute norms
    norms = np.linalg.norm(xt, axis=1)
    keep = norms**2 > threshold

    # Normalize and select
    xt = xt[keep]
    norms = norms[keep]
    if xt.size == 0:
        return [], 1
    xt /= norms[:, None]

    return xt, norms.min()


def _fill_heff_hermitian(heff, ax, xt, axt):
    # Stack active blocks
    nrow = len(axt)
    row1 = len(ax)
    row0 = row1 - nrow

    # === Block A: lower-right (nrow x nrow), symmetric ===
    block_A = xt @ axt.T.conj()  # shape (nrow, nrow)
    heff[row0:row1, row0:row1] = (block_A + block_A.T.conj()) / 2

    # === Block B: off-diagonal (row0 x nrow), symmetric ===
    block_B = xt @ ax[:row0].T.conj()  # shape (nrow, row0)
    heff[row0:row1, :row0] = block_B
    heff[:row0, row0:row1] = block_B.T.conj()

    return heff
